{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUSA8001- Programming Task 1  \n",
    "\n",
    "**Assignment Points**: 100  \n",
    "**Submission**: Provide your answers in this notebook and submit it via iLearn\n",
    "\n",
    "- Where a question requires a written answer provide your solution in Markdown in the cells under each question.\n",
    "- Comment out your print statements unless you are explicitly asked to print your output. \n",
    "- 5 marks will be deducted for printed outputs that are not asked for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Assignment\n",
    "\n",
    "- For this assignment there are two files in the `data` folder `credit_record.csv` and `application_record.csv` where bank clients are related by the `ID` column.\n",
    "\n",
    "- In `application_record.csv` we have the following variables\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number      |         |\n",
    "| AMT_INCOME   | Annual income  |  |\n",
    "| NAME_INCOME_TYPE   | Income Source |  |\n",
    "| NAME_EDUCATION_TYPE   | Level of Education  |  |\n",
    "| CODE_GENDER   | Applicant's Gender   |  |\n",
    "| FLAG_OWN_CAR | Car Ownership |  | \n",
    "| CNT_CHILDREN | Number of Children | |\n",
    "| FLAG_OWN_REALTY | Real Estate Ownership | | \n",
    "| NAME_FAMILY_STATUS | Relationship Status | | \n",
    "| NAME_HOUSING_TYPE | Housing Type | | \n",
    "| DAYS_BIRTH | No. of Days | Count backwards from current day (0), -1 means yesterday\n",
    "| DAYS_EMPLOYED | No. of Days | Count backwards from current day (0). If positive, it means the person is currently unemployed.\n",
    "| FLAG_MOBIL | Mobile Phone Ownership | | \n",
    "| FLAG_WORK_PHONE | Work Phone Ownership | | \n",
    "| FLAG_PHONE | Landline Phone Ownership | | \n",
    "| FLAG_EMAIL | Landline Phone Ownership | | \n",
    "| OCCUPATION_TYPE | Occupation | | \n",
    "| CNT_FAM_MEMBERS | Count of Family Members | |\n",
    "\n",
    "\n",
    "\n",
    "- In `credit_record.csv` we have the following variables\n",
    "\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number | |\n",
    "| MONTHS_BALANCE | Number of months in the past from now when STATUS is measured | 0 = current month, -1 = last month, -2 = two months ago, etc.|\n",
    "| STATUS | Number of days a payment is past due | 0: 1-29 days past due 1: 30-59 days past due 2: 60-89 days overdue 3: 90-119 days overdue 4: 120-149 days overdue 5: Overdue or bad debts, write-offs for more than 150 days C: paid off that month X: No loan for the month |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 1: Reading, Summarising and Cleaning Data (Total Marks: 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** \n",
    "\n",
    "1. Import the `application_record.csv` and `credit_record.csv` files from `data` folder into pandas DataFrames named `df_application` and `df_credit`, respectively. (1 mark)\n",
    "\n",
    "2. How many rows are there in `df_application` and `df_credit`, respectively? Provide your answers with print() and state them in Markdown text. (1 mark)\n",
    "\n",
    "3. How many unique bank clients are there in `df_application` and `df_credit`? Provide your answers with print() and state them in Markdown text. (1 mark)\n",
    "\n",
    "4. Add the records from `df_credit` to `df_application` by merging the data from the two DataFrames on the `ID` column, and output the joint data into a new DataFrame named `df`. Hint: Use `merge` function from pandas by setting `how` parameter to `inner` (4 marks) \n",
    "\n",
    "5. How many rows and how many unique clients are there now in `df`? (1 mark)\n",
    "\n",
    "6. How are multiple rows for each `ID` in `df` different? Answer in Markdown text. (2 mark) \n",
    "\n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df_application is  438445\n",
      "Number of rows in df_credit is  1047185\n",
      "Number of unique bank clients in df_application is  438398\n",
      "Number of unique bank clients in df_credit is  45924\n",
      "df has 776325 rows\n",
      "there are 36396 unique clients now in df\n"
     ]
    }
   ],
   "source": [
    "# ---- provide your code here -----\n",
    "# This code file has to be stored at the same folder and same folder level as the datas\n",
    "# Question 1.1\n",
    "\n",
    "import pandas as pd #import pandas lib\n",
    "\n",
    "df_application=pd.read_csv('application_record.csv') #import application record \n",
    "\n",
    "df_credit=pd.read_csv('credit_record.csv')  #import credit record\n",
    "\n",
    "#Question 1.2\n",
    "\n",
    "#count column for df_application\n",
    "print(\"Number of rows in df_application is \", len(df_application))\n",
    "\n",
    "#count column for df_credit\n",
    "print(\"Number of rows in df_credit is \", len(df_credit))\n",
    "\n",
    "#Question 1.3\n",
    "\n",
    "#count number of unique bank clients for df_application\n",
    "print(\"Number of unique bank clients in df_application is \", len(df_application['ID'].unique()))\n",
    "#count number of unique bank clients for df_credit\n",
    "print(\"Number of unique bank clients in df_credit is \", len(df_credit['ID'].unique()))\n",
    "\n",
    "#Question 1.4\n",
    "\n",
    "df=pd.merge(df_application,df_credit, how= 'inner')\n",
    "\n",
    "#Question 1.5\n",
    "\n",
    "print(f\"df has {len(df)} rows\") #count number of rows\n",
    "print(f\"There are {len(df['ID'].unique())} unique clients now in df\")   #count number of unique clients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your written answer here ----\n",
    "\n",
    "2.\n",
    "Number of rows in df_application is  438445\n",
    "\n",
    "Number of rows in df_credit is  1047185\n",
    "\n",
    "3. \n",
    "Number of unique bank clients in df_application is  438398\n",
    "Number of unique bank clients in df_credit is  45924\n",
    "\n",
    "5. \n",
    "'df' has 776325 rows\n",
    "\n",
    "There are 36396 unique clients now in 'df'\n",
    "\n",
    "6. \n",
    "According to the display of 'df' data, we can see that for each unique ID, there can be multiple rows with similar data in the other column headings except for 'MONTHS_BALANCE' column. \n",
    "\n",
    "This can be explained as the same customer may deposit or withdraw money from the bank multiple time during a period, resulting in the fluctuation of their bank balance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question 2.**\n",
    "\n",
    "1. Change the values of `STATUS` in `df` according to the following mapping: {C, X, 0} -> 0 and {1, 2, 3, 4, 5} -> 1 making sure that the new values of 0 and 1 are encoded as integers. (2 marks)\n",
    "\n",
    "2. Create a new *numpy* array called `list_of_past_due` that includes the unique ID numbers of clients whose `STATUS = 1` at any point during the last 12 months (hint: count the current month as the first month). (2 marks) \n",
    "\n",
    "3. Create a new DataFrame called `df_final` that contains the rows of `df` for which the `ID` is in `list_of_past_due`, keeping only one row for each `ID` (hint: keep the first duplicate row). How many rows do you have in `df_final`? Answer using both print() function and in Markdown text. (hint: find out about `isin()` function in pandas.) (2 marks)\n",
    "\n",
    "4. Add a new column `y = 1` for all the rows in `df_final`. (1 marks)\n",
    "\n",
    "5. Increase `df_final` to a total of 4,500 rows by adding rows from `df` with unique `ID`s which are not in `list_of_past_due`. To do this start adding the rows from the beginning of `df`. (hint: learn what `~`, i.e. tilde sign, does in pandas). (2 marks) \n",
    "\n",
    "6. Fill the missing values of `y` in `df_final` with zeros. Remove `STATUS` and `MONTHS_BALANCE` from `df_final`. (1 mark)\n",
    "\n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_13288\\373365566.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['STATUS'].replace(to_replace={\"C\",\"X\",0},value=0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5008831 5008872 5008912 ... 5149834 5150049 5150337]\n",
      "1737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_13288\\373365566.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_final['y'].replace(to_replace=np.nan,value=0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# ---- provide your code here -----\n",
    "\n",
    "#Question 2.1\n",
    "\n",
    "#Method 1: Using replace\n",
    "df['STATUS'].replace(to_replace={\"C\",\"X\",0},value=0, inplace=True)\n",
    "df['STATUS'].replace(to_replace=list(range(1,6)),value=1, inplace=True)\n",
    "\n",
    "#Medthod 2: Using map\n",
    "status_mapping={'C':0,'X':0, '0':0, '1':1,'2':1,'3':1,'4':1,'5':1}\n",
    "df['STATUS']=df['STATUS'].map(status_mapping)\n",
    "\n",
    "\n",
    "#Question 2.2\n",
    "\n",
    "import numpy as np\n",
    "list_of_past_due = df['ID'][(df['STATUS'] == 1) & (df['MONTHS_BALANCE'] > -12)].unique()\n",
    "\n",
    "#make sure list_of_past_due is numpy array\n",
    "if isinstance(list_of_past_due, np.ndarray):\n",
    "    pass\n",
    "else:\n",
    "    list_of_past_due=list_of_past_due.to_numpy()\n",
    "    \n",
    "#print list_of_past_due\n",
    "print(list_of_past_due)\n",
    "\n",
    "#QUestion 2.3\n",
    "\n",
    "df_final = df[df['ID'].isin(list_of_past_due)].drop_duplicates(subset='ID', keep='first')\n",
    "print(len(df_final))\n",
    "\n",
    "#Question 2.4\n",
    "\n",
    "df_final['y'] = 1\n",
    "\n",
    "#Question 2.5\n",
    "\n",
    "#creating a subarray that contains the rows of `df` for which the `ID` is NOT in `list_of_past_due`, keeping only one row for each `ID`\n",
    "df_sub = df[~df['ID'].isin(list_of_past_due)].drop_duplicates(subset='ID', keep='first')\n",
    "df_sub=df_sub.head(4500-len(df_final))\n",
    "df_final=pd.concat([df_final,df_sub],ignore_index=True)\n",
    "\n",
    "\n",
    "#Question 2.6\n",
    "\n",
    "df_final.drop([\"STATUS\",\"MONTHS_BALANCE\"], axis='columns', inplace=True)  #remove STATUS AND MONTHS_BALANCE FROM DF_FINALS\n",
    "df_final['y'].replace(to_replace=np.nan,value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your written answer here ----\n",
    "\n",
    "3.3 \n",
    "\n",
    "According to the result of print(len(df_final)), which outputs the length (or in this case, number of rows) of df_final variable, there are 1737 rows in the df_final variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 3**. \n",
    "1. Delete `ID` column from `df_final` and reset its index. (1 marks)\n",
    "2. Assuming that `NAME_EDUCATION_TYPE` is the only ordinal variable in `df_final`, which variables are numeric and which ones are nominal? Answer this question by copying and completing the following table (6 marks)\n",
    "\n",
    "|Variable type|Numbers of features|Features' list|\n",
    "| --- | --- | --- |\n",
    "|Numeric:|||\n",
    "|Ordinal:|1| NAME_EDUCATION_TYPE |\n",
    "|Nominal:|||\n",
    "\n",
    "3. Using appropriate functions find and comment on the missing values in `df_final` (3 marks)   \n",
    "\n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values: \n",
      " CODE_GENDER               0\n",
      "FLAG_OWN_CAR              0\n",
      "FLAG_OWN_REALTY           0\n",
      "AMT_INCOME                0\n",
      "NAME_FAMILY_STATUS        0\n",
      "NAME_INCOME_TYPE          0\n",
      "DAYS_BIRTH                0\n",
      "NAME_HOUSING_TYPE         0\n",
      "FLAG_WORK_PHONE           0\n",
      "FLAG_PHONE                0\n",
      "DAYS_EMPLOYED             0\n",
      "FLAG_MOBIL                0\n",
      "FLAG_EMAIL                0\n",
      "CNT_FAM_MEMBERS           0\n",
      "y                         0\n",
      "CNT_CHILDREN             74\n",
      "OCCUPATION_TYPE        1354\n",
      "NAME_EDUCATION_TYPE    1831\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ---- provide your code here ----\n",
    "#3.1\n",
    "df_final.drop(\"ID\", axis='columns', inplace=True)\n",
    "df_final.reset_index(drop= True)\n",
    "\n",
    "#3.3\n",
    "df_final.isnull() #print data rows containing NULL values\n",
    "print('Missing Values: \\n',df_final.isnull().sum().sort_values()) #find number of Null values for each cloumn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your written answer here ----\n",
    "\n",
    "3.2\n",
    "\n",
    "|Variable type|Numbers of features|Features' list|\n",
    "| --- | --- | --- |\n",
    "|Numeric:|5| CNT_CHILDREN, AMT_INCOME, DAYS_BIRTH, DAYS_EMPLOYED, CNT_FAM_MEMBERS |\n",
    "|Ordinal:|1| NAME_EDUCATION_TYPE |\n",
    "|Nominal:|12| CODE_GENDER, FLAG_OWN_CAR, FLAG_OWN_REALITY, NAME_INCOME_TYPE, NAME_FAMILY_STATUS, NAME_HOUSING_TYPE, OCCUPATION_TYPE, FLAG_MOBIL, FLAG_WORK_PHONE, FLAG_PHONE, FLAG_EMAIL, y|\n",
    "\n",
    "3.3\n",
    "\n",
    "The missing values in df_final are in three columns (listed in increasing order of missing values for each column): CNT_CHILDREN (74 missing values), OCCUPATION_TYPE (1,354 missing values), and NAME_EDUCATION_TYPE (1,831 missing values). To fill in these null values, we need to encode the data in these columns (if necessary) and replace the blank cells with the following:\n",
    "\n",
    "CNT_CHILDREN: Use the median of the existing values. Since the number of children must be numeric and a positive integer, choosing the median ensures that these criteria are met.\n",
    "\n",
    "OCCUPATION_TYPE: Use the mode or the most frequent value. As the type of occupation is nominal, the mode is the most suitable option because the encoded values do not need to represent any order among the listed jobs.\n",
    "\n",
    "NAME_EDUCATION_TYPE: Use the mode or the most frequent value. Although the type of education is ordinal, meaning it can be arranged in a specific order, the mode is preferable in this case. Using the median would require initial encoding of the data, which will be addressed in Question 5â€”one question after the data replacement question. Since mode does not require this additional step, it is the more practical choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 2: Imputing missing values and dealing with categorical features (Total Marks: 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** \n",
    "1. Use an appropriate `pandas` function to impute missing values in `df_final` (15 marks)\n",
    "    - Take into consideration the type of each variable and the best practices we discussed in class/lecture notes\n",
    "\n",
    "(Total: 15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_13288\\1406477015.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_final['CNT_CHILDREN'].fillna(df_final['CNT_CHILDREN'].median(axis=0),inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_13288\\1406477015.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_final['NAME_EDUCATION_TYPE'].fillna(df_final['NAME_EDUCATION_TYPE'].mode()[0],inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_13288\\1406477015.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_final['OCCUPATION_TYPE'].fillna(df_final['OCCUPATION_TYPE'].mode()[0],inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# ---- provide your code here -----\n",
    "#replace NULL valies using fillna\n",
    "df_final['CNT_CHILDREN'].fillna(df_final['CNT_CHILDREN'].median(axis=0),inplace=True)\n",
    "df_final['NAME_EDUCATION_TYPE'].fillna(df_final['NAME_EDUCATION_TYPE'].mode()[0],inplace=True)\n",
    "df_final['OCCUPATION_TYPE'].fillna(df_final['OCCUPATION_TYPE'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 5**. Convert the values in `NAME_EDUCATION_TYPE` as follows\n",
    "- Lower secondary -> 1\n",
    "- Secondary / secondary special -> 2\n",
    "- Incomplete higher -> 3\n",
    "- Higher education -> 4\n",
    "\n",
    "\n",
    "(Total: 5 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_13288\\1481117792.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_final['NAME_EDUCATION_TYPE'].replace(to_replace=\"Higher education\",value=int(4), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# ---- provide your code here -----\n",
    "\n",
    "df_final['NAME_EDUCATION_TYPE'].replace(to_replace=\"Lower secondary\",value=int(1), inplace=True)\n",
    "df_final['NAME_EDUCATION_TYPE'].replace(to_replace=\"Secondary / secondary special\",value=int(2), inplace=True)\n",
    "df_final['NAME_EDUCATION_TYPE'].replace(to_replace=\"Incomplete higher\",value=int(3), inplace=True)\n",
    "df_final['NAME_EDUCATION_TYPE'].replace(to_replace=\"Higher education\",value=int(4), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 6**. \n",
    "\n",
    "Add dummy variables to `df_final` for all of the nominal features which are currently stored as string (text). \n",
    "- Make sure to delete the original variables from the dataframe\n",
    "- Drop the first column from each set of created dummy variable, i.e. for each feature\n",
    "\n",
    "\n",
    "\n",
    "(Total: 10 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- provide your code here -\n",
    "list_of_heading=df_final.columns\n",
    "for i in list_of_heading:\n",
    "    if df_final[i].dtype=='object':\n",
    "        one_hot = pd.get_dummies(df_final[[i]], dtype = int, drop_first = True)\n",
    "        df_final.drop(i,axis='columns',inplace=True)\n",
    "        df_final=df_final.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   S_  column1_a  column1_c  column1_d  column2_a  column2_c  column2_d\n",
      "0   1       True      False      False      False      False       True\n",
      "1   2      False       True      False       True      False      False\n",
      "2   3      False      False       True      False       True      False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "diff = pd.DataFrame({'R': ['a', 'c', 'd'], \n",
    "                     'T': ['d', 'a', 'c'],\n",
    "                     'S_': [1, 2, 3]})\n",
    " \n",
    "print(pd.get_dummies(diff, prefix=['column1', 'column2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 3 Preparing X and y arrays (Total Marks: 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**. \n",
    "\n",
    "1. Create a numpy array named `y` from the `y` column of `df_final` making sure that the values of the array `y` are stored as integers (3 marks)   \n",
    "2. Create a numpy array named `X`  from all the remaining features in `df_final` (2 marks)   \n",
    "\n",
    "(Total: 5 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- provide your code here -----\n",
    "\n",
    "#7.1\n",
    "y = df_final['y'].astype(int).values\n",
    "\n",
    "#7.2\n",
    "X = df_final.drop(columns=['y'], inplace=False).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 8**. \n",
    "\n",
    "1. Use an appropriate scikit-learn library we used in class to create `y_train`, `y_test`, `X_train` and `X_test` by splitting the data into 75% train and 25% test datasets (2.5 marks) \n",
    "    - Set random_state to 8 and stratify the subsamples so that train and test datasets have roughly equal proportions of the target's class labels \n",
    "2. Standardise the data using `StandardScaler` library (2.5 marks)   \n",
    "\n",
    "(Total: 5 marks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- provide your code here -----\n",
    "#8.1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 8, stratify = y)\n",
    "\n",
    "#8.2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.set_printoptions(precision=3, suppress = True) # pretty printing\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_scaled = sc.transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 4. Logistic Regression and Random Forest Classifiers and Accuracies (Total Marks: 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9**. \n",
    "\n",
    "1. Train a Logistic Regression Classifier on standardised data (5 marks)\n",
    "    - Set `random_state` to 10 (don't change any other parameters)\n",
    "    - Compute and print training and test dataset accuracies   \n",
    "2. Train a Random Forest Classifier on standardised data (5 marks)\n",
    "    - Set `random_state` to 10 (don't change any other parameters)\n",
    "    - Compute and print training and test dataset accuracies\n",
    "\n",
    "When printing accuracies round the values to three decimal places.      \n",
    "\n",
    "(Total: 10 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training dataset = 0.660\n",
      "Accuracy for test dataset = 0.660\n",
      "Accuracy for training dataset = 0.9771852\n",
      "Accuracy for test dataset = 0.8871111\n"
     ]
    }
   ],
   "source": [
    "# ---- provide your code here -----\n",
    "#9.1\n",
    "\n",
    "#training logistic model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=10) \n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "#printing accuracy\n",
    "print(f'Accuracy for training dataset = {lr.score(X_train_scaled, y_train):.3f}')\n",
    "print(f'Accuracy for test dataset = {lr.score(X_test_scaled, y_test):.3f}')\n",
    "\n",
    "#9.2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(random_state=10)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "#printing accuracy\n",
    "print(f'Accuracy for training dataset = {forest.score(X_train, y_train):.7f}')\n",
    "print(f'Accuracy for test dataset = {forest.score(X_test, y_test):.7f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10**. \n",
    "\n",
    "a) Comment and compare the training and test accuracies for each classifier computed in Question 9. What can we say about the extent of overfitting for each classifier? (5 marks)   \n",
    "b) Comment and compare the accuracies across the two classifiers. Which classifier provides better forecasts? (5 marks)   \n",
    "c) What can you say about the presence of nonlinearities in the dataset? (10 marks)   \n",
    "\n",
    "(Total: 20 marks)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your written answer here ----\n",
    "\n",
    "a)\n",
    "\n",
    "\"Overfitting\" is defined when a model  captures \"patterns\" in the training data that do not repeat in new data. Thus, if a model has a significantly high accuracy on training dataset, following by a much smaller accuracy test dataset, we can conclude that model has a high extent for overfiting.\n",
    "\n",
    "For logistic regression, the accuracy for training dataset (around 66%) is higher than that for test dataset (around 65.96%). This indicates that the logistic regression has achieved a nearly match accuracy when learnining the model from training dataset and use it on dataset, demonstrating a moderate overfitting level\n",
    "\n",
    "On the other hand, for random forest classifier, the accuracy for training dataset (around 97.7%) is higher than that for test dataset (around 90%). Moreover, the surge in accuracy from training dataset to test dataset is more comparable in random forest classifier (around 97.7%-88.8%=9%) compared to logistic regression model (around 66%-65.96%=0.04%). This significant weight on training dataset accuracy (nearly perfect) demonstrate a higher overfitting rate compared to logistic regression\n",
    "\n",
    "In general, while logistic regression has a lower learning accuracy compared to its rival, the balance between accuracy in test and training dataset makes it a less overfitting model.\n",
    "\n",
    "b)\n",
    "\n",
    "Comparing between the 2 classifiers, we can observe that logistic regression has a lower accuracy in test dataset (about 65%) compared to random forest classifier (around 88.8%). As a result, we can conclude that random forest classifier provide better forecast than logistic regression classifier\n",
    "\n",
    "c)\n",
    "\n",
    "The presence of nonlinearities in the dataset reduces the accuracy of the logistic regression classifier while random forest classifier is not affected. This is because logistic regression is a linear classifier, which computes a straight-line decision boundary to separate and classify data. However, where data points are not perfectly separable, this classifier results in low accuracy (for example a data labelled \"A\" is classified as \"B\" when it lies in the \"A\" area separable by decision boundary).\n",
    "\n",
    "Conversely, the random forest classifier is capable of capturing isolated points with less extreme classification probabilities. Naturally, random forest classifier ensembles approach, which combines multiple smaller classifiers from each decision tree, results in a complex decision boundary that effectively captures the nonlinear data. Thus, it provides a more flexible decision boundary by averaging multiple decision trees, which helps in capturing the overall structure of the data, including nonlinearities. In short, the accuracy of this classifier is not related to the nonlinear property of the dataset, making it a more reliable model for prediction in this case.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
